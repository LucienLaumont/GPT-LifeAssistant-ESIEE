{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<h1 style=\"text-align: center; font-weight: bold; color:rgb(255, 255, 255);\">Final Project: Building a Daily Life Assistant</h1>\n",
    "\n",
    "<p style=\"font-size: 25px; line-height: 1.6; text-align: justify; max-width: 1200px; margin: 0 auto; margin-bottom: 20px;\">\n",
    "    This project aims to create a practical AI assistant using an instruction fine-tuned GPT-2 model. \n",
    "    The assistant will perform daily tasks such as scheduling, answering questions, and providing personalized recommendations.\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size: 20px; line-height: 1.8; max-width: 1000px; margin: 0 auto;\">\n",
    "    <li><strong>Model Architecture & Pretraining</strong>: Understanding GPT-2â€™s architecture and pretraining process.</li>\n",
    "    <li><strong>Instruction Fine-Tuning</strong>: Training the model with instruction-response pairs for enhanced task performance.</li>\n",
    "    <li><strong>Evaluation & Refinement</strong>: Assessing the model's output and iterating for better results.</li>\n",
    "    <li><strong>Practical Application</strong>: Implementing the model in real-world scenarios such as daily task management.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Environment Setup**\n",
    "\n",
    "We start by loading the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==2.1.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: accelerate==1.3.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs==2.4.4 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 3)) (2.4.4)\n",
      "Requirement already satisfied: aiohttp==3.11.11 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 4)) (3.11.11)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: asttokens==3.0.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 7)) (1.6.3)\n",
      "Requirement already satisfied: attrs==25.1.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 8)) (25.1.0)\n",
      "Requirement already satisfied: certifi==2024.12.14 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 9)) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 10)) (3.4.1)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 11)) (0.4.6)\n",
      "Requirement already satisfied: comm==0.2.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: contourpy==1.3.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: cycler==0.12.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 14)) (0.12.1)\n",
      "Requirement already satisfied: datasets==3.2.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 15)) (3.2.0)\n",
      "Requirement already satisfied: debugpy==1.8.12 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 16)) (1.8.12)\n",
      "Requirement already satisfied: decorator==5.1.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 17)) (5.1.1)\n",
      "Requirement already satisfied: dill==0.3.8 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 18)) (0.3.8)\n",
      "Requirement already satisfied: executing==2.1.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 19)) (2.1.0)\n",
      "Requirement already satisfied: filelock==3.16.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 20)) (3.16.1)\n",
      "Requirement already satisfied: flatbuffers==24.12.23 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 21)) (24.12.23)\n",
      "Requirement already satisfied: fonttools==4.55.3 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 22)) (4.55.3)\n",
      "Requirement already satisfied: frozenlist==1.5.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 23)) (1.5.0)\n",
      "Requirement already satisfied: fsspec==2024.9.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 24)) (2024.9.0)\n",
      "Requirement already satisfied: gast==0.6.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 25)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 26)) (0.2.0)\n",
      "Requirement already satisfied: grpcio==1.69.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 27)) (1.69.0)\n",
      "Requirement already satisfied: h5py==3.12.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 28)) (3.12.1)\n",
      "Requirement already satisfied: huggingface-hub==0.27.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 29)) (0.27.1)\n",
      "Requirement already satisfied: idna==3.10 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 30)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 31)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.31.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 32)) (8.31.0)\n",
      "Requirement already satisfied: jedi==0.19.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 33)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.5 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 34)) (3.1.5)\n",
      "Requirement already satisfied: joblib==1.4.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 35)) (1.4.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 36)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 37)) (5.7.2)\n",
      "Requirement already satisfied: keras==3.8.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 38)) (3.8.0)\n",
      "Requirement already satisfied: kiwisolver==1.4.8 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 39)) (1.4.8)\n",
      "Requirement already satisfied: libclang==18.1.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 40)) (18.1.1)\n",
      "Requirement already satisfied: Markdown==3.7 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 41)) (3.7)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 42)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 43)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib==3.10.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 44)) (3.10.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 45)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 46)) (0.1.2)\n",
      "Requirement already satisfied: ml-dtypes==0.4.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 47)) (0.4.1)\n",
      "Requirement already satisfied: mpmath==1.3.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 48)) (1.3.0)\n",
      "Requirement already satisfied: multidict==6.1.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 49)) (6.1.0)\n",
      "Requirement already satisfied: multiprocess==0.70.16 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 50)) (0.70.16)\n",
      "Requirement already satisfied: namex==0.0.8 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 51)) (0.0.8)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 52)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 53)) (3.4.2)\n",
      "Requirement already satisfied: numpy==2.0.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 54)) (2.0.2)\n",
      "Requirement already satisfied: opt_einsum==3.4.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 55)) (3.4.0)\n",
      "Requirement already satisfied: optree==0.14.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 56)) (0.14.0)\n",
      "Requirement already satisfied: packaging==24.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 57)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 58)) (2.2.3)\n",
      "Requirement already satisfied: parso==0.8.4 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 59)) (0.8.4)\n",
      "Requirement already satisfied: pillow==11.1.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 60)) (11.1.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 61)) (4.3.6)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.49 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 62)) (3.0.49)\n",
      "Requirement already satisfied: propcache==0.2.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 63)) (0.2.1)\n",
      "Requirement already satisfied: protobuf==5.29.3 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 64)) (5.29.3)\n",
      "Requirement already satisfied: psutil==6.1.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 65)) (6.1.1)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 66)) (0.2.3)\n",
      "Requirement already satisfied: pyarrow==19.0.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 67)) (19.0.0)\n",
      "Requirement already satisfied: Pygments==2.19.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 68)) (2.19.1)\n",
      "Requirement already satisfied: pyparsing==3.2.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 69)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 70)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 71)) (1.0.1)\n",
      "Requirement already satisfied: pytz==2024.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 72)) (2024.2)\n",
      "Requirement already satisfied: pywin32==308 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 73)) (308)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 74)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.2.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 75)) (26.2.0)\n",
      "Requirement already satisfied: regex==2024.11.6 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 76)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.3 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 77)) (2.32.3)\n",
      "Requirement already satisfied: rich==13.9.4 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 78)) (13.9.4)\n",
      "Requirement already satisfied: safetensors==0.5.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 79)) (0.5.2)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 80)) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.15.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 81)) (1.15.1)\n",
      "Requirement already satisfied: setuptools==75.8.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 82)) (75.8.0)\n",
      "Requirement already satisfied: six==1.17.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 83)) (1.17.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 84)) (0.6.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 85)) (1.13.1)\n",
      "Requirement already satisfied: tensorboard==2.18.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 86)) (2.18.0)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 87)) (0.7.2)\n",
      "Requirement already satisfied: tensorflow==2.18.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 88)) (2.18.0)\n",
      "Requirement already satisfied: tensorflow_intel==2.18.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 89)) (2.18.0)\n",
      "Requirement already satisfied: termcolor==2.5.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 90)) (2.5.0)\n",
      "Requirement already satisfied: tf_keras==2.18.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 91)) (2.18.0)\n",
      "Requirement already satisfied: threadpoolctl==3.5.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 92)) (3.5.0)\n",
      "Requirement already satisfied: tiktoken==0.8.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 93)) (0.8.0)\n",
      "Requirement already satisfied: tokenizers==0.21.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 94)) (0.21.0)\n",
      "Requirement already satisfied: torch==2.5.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 95)) (2.5.1)\n",
      "Requirement already satisfied: tornado==6.4.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 96)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 97)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 98)) (5.14.3)\n",
      "Requirement already satisfied: transformers==4.48.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 99)) (4.48.0)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 100)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2025.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 101)) (2025.1)\n",
      "Requirement already satisfied: urllib3==2.3.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 102)) (2.3.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 103)) (0.2.13)\n",
      "Requirement already satisfied: Werkzeug==3.1.3 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 104)) (3.1.3)\n",
      "Requirement already satisfied: wheel==0.45.1 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 105)) (0.45.1)\n",
      "Requirement already satisfied: wrapt==1.17.2 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 106)) (1.17.2)\n",
      "Requirement already satisfied: xxhash==3.5.0 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 107)) (3.5.0)\n",
      "Requirement already satisfied: yarl==1.18.3 in c:\\users\\lucie\\documents\\cours\\e5\\llm\\gpt-lifeassistant-esiee\\env\\lib\\site-packages (from -r requirements.txt (line 108)) (1.18.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucie\\Documents\\Cours\\E5\\llm\\GPT-LifeAssistant-ESIEE\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import torch\n",
    "import tiktoken\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "from lib_labs.gpt_download import download_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading the Pretrained GPT-2 Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "MODEL_DIR = os.getenv(\"MODEL_DIR\")\n",
    "MODEL_SIZE = os.getenv(\"MODEL_SIZE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TÃ©lÃ©chargement du modÃ¨le gpt2-large dans model...\n",
      "ModÃ¨le gpt2-large tÃ©lÃ©chargÃ© et sauvegardÃ© dans model.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = download_gpt2(MODEL_DIR,MODEL_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Testing the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the capital of Spain ?\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = inputs.input_ids\n",
    "attention_mask = inputs.attention_mask\n",
    "\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the capital of Spain ?\\n\\nThe capital of Spain is Madrid.\\n\\nWhat is the capital of France ?\\n\\nThe capital of France is Paris.\\n\\nWhat is the capital of Germany ?\\n\\nThe capital of Germany is Berlin.\\n\\nWhat is the capital of Italy ?\\n\\nThe capital of Italy is Rome.\\n\\nWhat is the capital of the Netherlands ?\\n\\nThe capital of the Netherlands is Amsterdam.\\n\\nWhat is the capital of the United Kingdom ?\\n\\nThe capital of the United Kingdom is London.\\n\\nWhat is the capital of the United States of America ?\\n\\nThe capital of the United States of America is Washington, D.C.\\n\\nWhat is the capital of the'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    input_ids = input_ids,\n",
    "    attention_mask = attention_mask,\n",
    "    pad_token_id = tokenizer.pad_token_id,\n",
    "    max_length = 150,\n",
    "    num_beams = 5,\n",
    "    temperature = 1,\n",
    "    top_k = 50,\n",
    "    do_sample = True\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handling Incomplete Responses from GPT-2**\n",
    "\n",
    "In some cases, GPT-2 provides an incomplete response. It starts a sentence but doesn't finish it. This is problematic because it negatively impacts the user experience. There are several solutions to address this issue:\n",
    "\n",
    "1. **Fine-tuning with examples of complete responses**: Train the model on a dataset that includes well-structured and complete answers to improve its behavior.\n",
    "\n",
    "2. **Post-processing generated responses**: Implement logic to analyze the output and request the model to continue if a response is detected as incomplete.\n",
    "\n",
    "3. **Adjusting generation parameters**: Modify parameters such as `max_length`, `temperature`, `top_k`, or `top_p` to increase the likelihood of producing complete and coherent answers.\n",
    "\n",
    "4. **Adding a contextual prefix**: Use a prompt like _\"Please provide a detailed and complete answer:\"_ before the main query to guide the model towards better responses.\n",
    "\n",
    "5. **Automatic verification with a script**: Create a script to detect incomplete responses and prompt the model to continue if necessary.\n",
    "\n",
    "\n",
    "We will choose to integrate a script to handle this issue. Additionally, during the fine-tuning process for a daily assistant, we will ensure that this concern is addressed in the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_incomplete_sentences(text):\n",
    "    \"\"\"\n",
    "    Slice the input text into sentences, keeping the formatting \n",
    "    (e.g., \\n, spaces), and remove incomplete phrases that do not \n",
    "    end with a proper punctuation mark.\n",
    "    \"\"\"\n",
    "    # Split the text while keeping the delimiters (e.g., .!?) and formatting\n",
    "    sentences = re.split(r'(?<=[.!?])(\\s+)', text)\n",
    "    \n",
    "    cleaned_text = \"\"\n",
    "    for i in range(0, len(sentences) - 1, 2):  # Process sentences with their trailing spaces\n",
    "        sentence = sentences[i]\n",
    "        trailing_space = sentences[i + 1]\n",
    "        if re.search(r'[.!?]$', sentence):  # Check if the sentence ends with valid punctuation\n",
    "            cleaned_text += sentence + trailing_space\n",
    "    \n",
    "    # Handle cases where the last part is an incomplete sentence\n",
    "    if len(sentences) % 2 != 0 and re.search(r'[.!?]$', sentences[-1]):\n",
    "        cleaned_text += sentences[-1]\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "\n",
      "What is the capital of Spain ?\n",
      "\n",
      "The capital of Spain is Madrid.\n",
      "\n",
      "What is the capital of France ?\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "What is the capital of Germany ?\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "What is the capital of Italy ?\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "What is the capital of the Netherlands ?\n",
      "\n",
      "The capital of the Netherlands is Amsterdam.\n",
      "\n",
      "What is the capital of the United Kingdom ?\n",
      "\n",
      "The capital of the United Kingdom is London.\n",
      "\n",
      "What is the capital of the United States of America ?\n",
      "\n",
      "The capital of the United States of America is Washington, D.C.\n",
      "\n",
      "What is the capital of the\n",
      "\n",
      "Cleaned Text:\n",
      "\n",
      "What is the capital of Spain ?\n",
      "\n",
      "The capital of Spain is Madrid.\n",
      "\n",
      "What is the capital of France ?\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "What is the capital of Germany ?\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "What is the capital of Italy ?\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "What is the capital of the Netherlands ?\n",
      "\n",
      "The capital of the Netherlands is Amsterdam.\n",
      "\n",
      "What is the capital of the United Kingdom ?\n",
      "\n",
      "The capital of the United Kingdom is London.\n",
      "\n",
      "What is the capital of the United States of America ?\n",
      "\n",
      "The capital of the United States of America is Washington, D.C.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_complete_sentences = clean_incomplete_sentences(generated_text)\n",
    "\n",
    "print(\"Original Text:\\n\")\n",
    "print(generated_text)\n",
    "print(\"\\nCleaned Text:\\n\")\n",
    "print(text_complete_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handling Redundant Sentences in GPT-Generated Text**\n",
    "\n",
    "GPT often generates sentences that are almost identical or convey similar information. This redundancy can make it challenging to filter out phrases with overlapping content. To address this issue, we will implement a script that detects and removes duplicate or nearly identical sentences.\n",
    "\n",
    "1. **Sentence Splitting**: \n",
    "   - The text will be divided into individual sentences using a delimiter (e.g., `.`, `!`, `?`).\n",
    "\n",
    "2. **Similarity Detection**:\n",
    "   - We will compare each sentence against others using a similarity metric, such as Levenshtein distance or cosine similarity on vector embeddings.\n",
    "\n",
    "3. **Duplicate Removal**:\n",
    "   - Sentences identified as duplicates or with high similarity scores will be removed, leaving only unique information.\n",
    "\n",
    "4. **Reconstruction**:\n",
    "   - The remaining unique sentences will be combined into a coherent, cleaned text while preserving the original format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def remove_redundant_sentences(text, similarity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Removes redundant or highly similar sentences from the given text, preserving formatting such as \\n and spaces, while keeping key sentences.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The input text containing potentially redundant sentences.\n",
    "        similarity_threshold (float): The cosine similarity threshold above which\n",
    "                                       sentences are considered redundant.\n",
    "\n",
    "    Returns:\n",
    "        str: Text with redundant sentences removed.\n",
    "    \"\"\"\n",
    "    # Split the text into sentences while preserving the delimiters and formatting\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "    # Vectorize the sentences using TF-IDF\n",
    "    vectorizer = TfidfVectorizer().fit_transform(sentences)\n",
    "\n",
    "    # Compute cosine similarity between all sentence pairs\n",
    "    similarity_matrix = cosine_similarity(vectorizer)\n",
    "\n",
    "    # Identify sentences to keep\n",
    "    sentences_to_keep = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # Check if the sentence is similar to any previously kept sentence\n",
    "        if all(similarity_matrix[i, j] < similarity_threshold for j in sentences_to_keep):\n",
    "            sentences_to_keep.append(i)\n",
    "\n",
    "    # Reconstruct the text with only unique sentences\n",
    "    unique_sentences = [sentences[i] for i in sentences_to_keep]\n",
    "    return '\\n'.join(unique_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "\n",
      "What is the capital of Spain ?\n",
      "\n",
      "The capital of Spain is Madrid.\n",
      "\n",
      "What is the capital of France ?\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "What is the capital of Germany ?\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "What is the capital of Italy ?\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "What is the capital of the Netherlands ?\n",
      "\n",
      "The capital of the Netherlands is Amsterdam.\n",
      "\n",
      "What is the capital of the United Kingdom ?\n",
      "\n",
      "The capital of the United Kingdom is London.\n",
      "\n",
      "What is the capital of the United States of America ?\n",
      "\n",
      "The capital of the United States of America is Washington, D.C.\n",
      "\n",
      "\n",
      "\n",
      "Cleaned Text:\n",
      "\n",
      "What is the capital of Spain ?\n",
      "The capital of Spain is Madrid.\n",
      "What is the capital of France ?\n",
      "The capital of France is Paris.\n",
      "What is the capital of Germany ?\n",
      "The capital of Germany is Berlin.\n",
      "What is the capital of Italy ?\n",
      "The capital of Italy is Rome.\n",
      "What is the capital of the Netherlands ?\n",
      "The capital of the Netherlands is Amsterdam.\n",
      "What is the capital of the United Kingdom ?\n",
      "The capital of the United Kingdom is London.\n",
      "What is the capital of the United States of America ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = remove_redundant_sentences(text_complete_sentences)\n",
    "\n",
    "print(\"Original Text:\\n\")\n",
    "print(text_complete_sentences)\n",
    "print(\"\\nCleaned Text:\\n\")\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Finetune The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "with open('prompt.json', 'r',encoding='utf8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the dataset\n",
    "def preprocess(example):\n",
    "    # Combine instruction, input, and output into a single text prompt\n",
    "    prompt = f\"Instruction: {example['instruction']}\\n\"\n",
    "    if example['input']:\n",
    "        prompt += f\"Input: {example['input']}\\n\"\n",
    "    prompt += f\"Output: {example['output']}\"\n",
    "    return {\"text\": prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 137/137 [00:00<00:00, 2187.32 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 3996.72 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 3: Split the dataset into training and evaluation sets\n",
    "train_data, eval_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert train and eval data into Hugging Face Datasets\n",
    "train_dataset = Dataset.from_list(train_data).map(preprocess)\n",
    "eval_dataset = Dataset.from_list(eval_data).map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 137/137 [00:00<00:00, 642.98 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, 959.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Tokenize the dataset\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT-2 does not have a pad token\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model_finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucie\\AppData\\Local\\Temp\\ipykernel_12504\\1756497383.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Define the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train the model\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Save the fine-tuned model\n",
    "\n",
    "# model.save_pretrained(\"./model_finetuned\")\n",
    "# tokenizer.save_pretrained(\"./model_finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
